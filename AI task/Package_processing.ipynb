{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing OpenCV and Tesseract libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.10'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pkg_resources\n",
    "pkg_resources.working_set.by_key['pytesseract'].version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can extract a cartboard box from image using visual processing. Only works when box is moving on a different color conveyor. Uses color separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('package.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "th = cv2.threshold(hsv[:,:,0],127,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "def get_region(image):\n",
    "    contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    black = np.zeros((image.shape[0], image.shape[1]), np.uint8)\n",
    "    mask = cv2.drawContours(black,[c],0,255, -1)\n",
    "    return mask\n",
    "\n",
    "mask = get_region(th)\n",
    "\n",
    "masked_img = cv2.bitwise_and(img, img, mask = mask)\n",
    "\n",
    "cv2.imwrite(\"masked_image.jpg\", masked_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Picture1.jpg.png\")\n",
    "height, width, channel = img.shape\n",
    "\n",
    "\n",
    "def process(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    img_blur = cv2.GaussianBlur(thresh, (5, 5), 2)\n",
    "    img_canny = cv2.Canny(img_blur, 0, 0)\n",
    "    return img_canny\n",
    "\n",
    "def get_contours(img):\n",
    "    contours, _ = cv2.findContours(process(img), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    r1, r2 = sorted(contours, key=cv2.contourArea)[-3:-1]\n",
    "    x, y, w, h = cv2.boundingRect(np.r_[r1, r2])\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    ROI = img[y:y+h, x:x+w]\n",
    "    cv2.imwrite('bounds.jpg', ROI)\n",
    "    return ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bounds.jpg'\n",
    "mainImage = cv2.imread(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method used for splitting image into 4 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitImage(image):\n",
    "    width = image.shape[1]\n",
    "    # Cut the image in half\n",
    "    width_cutoff = width // 2\n",
    "    left1 = image[:, :width_cutoff]\n",
    "    right1 = image[:, width_cutoff:]\n",
    "    ##########################################\n",
    "    # Processing left side\n",
    "    ##########################################\n",
    "    # Rotating left side by 90 degrees and splitting it in half\n",
    "    image = cv2.rotate(left1, cv2.ROTATE_90_CLOCKWISE)\n",
    "    width = image.shape[1]\n",
    "    width_cutoff = width // 2\n",
    "    l1 = image[:, :width_cutoff]\n",
    "    l2 = image[:, width_cutoff:]\n",
    "    # Restoring rotation saving parts of image as new images\n",
    "    l1 = cv2.rotate(l1, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(\"bottom_left.jpg\", l1)\n",
    "    l2 = cv2.rotate(l2, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(\"top_left.jpg\", l2)\n",
    "    ##########################################\n",
    "    # Processing right side\n",
    "    ##########################################\n",
    "    # Rotating right side by 90 degrees and splitting it in half\n",
    "    image = cv2.rotate(right1, cv2.ROTATE_90_CLOCKWISE)\n",
    "    width = image.shape[1]\n",
    "    width_cutoff = width // 2\n",
    "    r1 = image[:, :width_cutoff]\n",
    "    r2 = image[:, width_cutoff:]\n",
    "    # Restoring rotation saving parts of image as new images\n",
    "    r1 = cv2.rotate(r1, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(\"bottom_right.jpg\", r1)\n",
    "    r2 = cv2.rotate(r2, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(\"top_right.jpg\", r2)\n",
    "    image_data = [l1, l2, r1, r2]\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming image using OpenCV and extracting numbers using Tesseract. The image is blurred, thresholded and diluted. Then Tesseract extracts test with flags to only search for digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(name, fileIsImage=False):\n",
    "    # If fileIsImage = False, reads image from file, otherwise assumes image is already given\n",
    "    if(not fileIsImage):\n",
    "        img = cv2.imread(name)\n",
    "    else:\n",
    "        img = name\n",
    "    # Converting image colorspace from BGR(Blue Green Red) to HSV(Hue Saturation Value) for processing\n",
    "    HSV_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # Splitting image values into 3 variables\n",
    "    h,s,v = cv2.split(HSV_img)\n",
    "    # Removing image noise using Gaussian Blur\n",
    "    v = cv2.GaussianBlur(v, (1,1), 0)\n",
    "    # Using Otsu's thresholding algorithm to clear up the image\n",
    "    thresh = cv2.threshold(v, 128, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    # Saving processed image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(1, 2))\n",
    "    # Dilating image\n",
    "    thresh = cv2.dilate(thresh, kernel)\n",
    "    cv2.imwrite(\"transformed.png\", thresh)\n",
    "    # Using tesseract to extract numbers\n",
    "    txt = pytesseract.image_to_string(thresh, config=\"--psm 6 digits\")\n",
    "    return txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    angle = 0\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText2(name, fileIsImage=False):\n",
    "    # If fileIsImage = False, reads image from file, otherwise assumes image is already given\n",
    "    if(not fileIsImage):\n",
    "        img = cv2.imread(name)\n",
    "    else:\n",
    "        img = name\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #noise removal\n",
    "    noise=cv2.medianBlur(gray,3)\n",
    "    # thresholding# converting it to binary image by Thresholding\n",
    "    # this step is require if you have colored image because if you skip this part\n",
    "    # then tesseract wonâ€™t able to detect text correctly and this will give incorrect #result\n",
    "    thresh = cv2.threshold(noise, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    # thresh = cv2.bitwise_not(thresh)\n",
    "    cv2.imwrite(\"transformed.png\", thresh)\n",
    "    # Using tesseract to extract numbers\n",
    "    # txt = pytesseract.image_to_string(thresh)\n",
    "    txt = pytesseract.image_to_string(thresh, config=\"--psm 6 digits\")\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504.832.89\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = 'frame6.png'\n",
    "mainImage = cv2.imread(filename)\n",
    "text = getText2(mainImage[220:400,300:,:], True)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['level', 'page_num', 'block_num', 'par_num', 'line_num', 'word_num', 'left', 'top', 'width', 'height', 'conf', 'text'])\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('frame3.png')\n",
    "\n",
    "d = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)\n",
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    if int(d['conf'][i]) > 60:\n",
    "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite('test555.png', img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACT: vid_1 has 11 boxes captured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getText2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6648\\3228428249.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#pic = get_contours(frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetText2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mframenbr\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getText2' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"vid_1.MOV\"\n",
    "\n",
    "vidcap = cv2.VideoCapture(path)\n",
    "success,frame = vidcap.read()\n",
    "framenbr = 0\n",
    "\n",
    "while success:\n",
    "    cv2.imwrite(\"frame%d.png\" % framenbr, frame[500:1020,1080:1680]) \n",
    "    success,frame = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    #pic = get_contours(frame)\n",
    "    text = getText2(frame[500:1020,1080:1680], True)\n",
    "    print(text)\n",
    "    framenbr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Tomas playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code loops through the video reading every {rateReduction}th frame.<br>\n",
    "video length: 44sec<br>\n",
    "executes in: 35sec<br>\n",
    "conclusion: quality too good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "path = \"vid_1.MOV\"\n",
    "vidcap = cv2.VideoCapture(path)\n",
    "rateReduction = 70\n",
    "framenbr = 0\n",
    "success,frame = vidcap.read()\n",
    "count = 0\n",
    "\n",
    "while success:\n",
    "    success, frame = vidcap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    cv2.imwrite(\"frame%d.png\" % framenbr, frame) \n",
    "    # text = getText2(frame[500:1020,1080:1680], True)\n",
    "    count += rateReduction # i.e. at 30 fps, this advances one second\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
    "    # print(text)\n",
    "    framenbr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found\n",
      "Not found\n",
      "Not found\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "searchID = '704.035.93'\n",
    "images = splitImage(mainImage)\n",
    "for image in images:\n",
    "    text = getText(image, True)\n",
    "    text = re.sub('[^\\d\\.]', '', text)\n",
    "    if(searchID in text):\n",
    "        print(\"Found\")\n",
    "        break\n",
    "    print(\"Not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a0efb84bc0a321a0c62beb86eaa0e460c332d667755e4a7f19165c6121589ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
