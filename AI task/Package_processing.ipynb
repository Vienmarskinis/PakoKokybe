{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing OpenCV and Tesseract libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can extract a cartboard box from image using visual processing. Only works when box is moving on a different color conveyor. Uses color separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('package.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "th = cv2.threshold(hsv[:,:,0],127,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "def get_region(image):\n",
    "    contours, hierarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(contours, key = cv2.contourArea)\n",
    "    black = np.zeros((image.shape[0], image.shape[1]), np.uint8)\n",
    "    mask = cv2.drawContours(black,[c],0,255, -1)\n",
    "    return mask\n",
    "\n",
    "mask = get_region(th)\n",
    "\n",
    "masked_img = cv2.bitwise_and(img, img, mask = mask)\n",
    "\n",
    "cv2.imwrite(\"masked_image.jpg\", masked_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"Picture1.jpg.png\")\n",
    "height, width, channel = img.shape\n",
    "\n",
    "\n",
    "def process(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    img_blur = cv2.GaussianBlur(thresh, (5, 5), 2)\n",
    "    img_canny = cv2.Canny(img_blur, 0, 0)\n",
    "    return img_canny\n",
    "\n",
    "def get_contours(img):\n",
    "    contours, _ = cv2.findContours(process(img), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    r1, r2 = sorted(contours, key=cv2.contourArea)[-3:-1]\n",
    "    x, y, w, h = cv2.boundingRect(np.r_[r1, r2])\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    ROI = img[y:y+h, x:x+w]\n",
    "    cv2.imwrite('bounds.jpg', ROI)\n",
    "    return ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'bounds.jpg'\n",
    "mainImage = cv2.imread(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method used for splitting image into 4 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitImage(image):\n",
    "    width = image.shape[1]\n",
    "    # Cut the image in half\n",
    "    width_cutoff = width // 2\n",
    "    left1 = image[:, :width_cutoff]\n",
    "    right1 = image[:, width_cutoff:]\n",
    "    ##########################################\n",
    "    # Processing left side\n",
    "    ##########################################\n",
    "    # Rotating left side by 90 degrees and splitting it in half\n",
    "    image = cv2.rotate(left1, cv2.ROTATE_90_CLOCKWISE)\n",
    "    width = image.shape[1]\n",
    "    width_cutoff = width // 2\n",
    "    l1 = image[:, :width_cutoff]\n",
    "    l2 = image[:, width_cutoff:]\n",
    "    # Restoring rotation saving parts of image as new images\n",
    "    l1 = cv2.rotate(l1, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(\"bottom_left.jpg\", l1)\n",
    "    l2 = cv2.rotate(l2, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(\"top_left.jpg\", l2)\n",
    "    ##########################################\n",
    "    # Processing right side\n",
    "    ##########################################\n",
    "    # Rotating right side by 90 degrees and splitting it in half\n",
    "    image = cv2.rotate(right1, cv2.ROTATE_90_CLOCKWISE)\n",
    "    width = image.shape[1]\n",
    "    width_cutoff = width // 2\n",
    "    r1 = image[:, :width_cutoff]\n",
    "    r2 = image[:, width_cutoff:]\n",
    "    # Restoring rotation saving parts of image as new images\n",
    "    r1 = cv2.rotate(r1, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(\"bottom_right.jpg\", r1)\n",
    "    r2 = cv2.rotate(r2, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    cv2.imwrite(\"top_right.jpg\", r2)\n",
    "    image_data = [l1, l2, r1, r2]\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming image using OpenCV and extracting numbers using Tesseract. The image is blurred, thresholded and diluted. Then Tesseract extracts test with flags to only search for digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(name, fileIsImage=False):\n",
    "    # If fileIsImage = False, reads image from file, otherwise assumes image is already given\n",
    "    if(not fileIsImage):\n",
    "        img = cv2.imread(name)\n",
    "    else:\n",
    "        img = name\n",
    "    # Converting image colorspace from BGR(Blue Green Red) to HSV(Hue Saturation Value) for processing\n",
    "    HSV_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    # Splitting image values into 3 variables\n",
    "    h,s,v = cv2.split(HSV_img)\n",
    "    # Removing image noise using Gaussian Blur\n",
    "    v = cv2.GaussianBlur(v, (1,1), 0)\n",
    "    # Using Otsu's thresholding algorithm to clear up the image\n",
    "    thresh = cv2.threshold(v, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    # Saving processed image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(1, 2))\n",
    "    # Dilating image\n",
    "    thresh = cv2.dilate(thresh, kernel)\n",
    "    # Using tesseract to extract numbers\n",
    "    txt = pytesseract.image_to_string(thresh, config=\"--psm 6 digits\")\n",
    "    return txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ". .\n",
      "-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = getText(filename, False)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-\n",
      "-\n",
      ".\n",
      "- . . . - 7 . . . - -\n",
      "\n",
      "\n",
      "\n",
      ". .\n",
      "-\n",
      "\n",
      ". -3\n",
      "\n",
      ".\n",
      "- 3\n",
      "1\n",
      "2\n",
      "-\n",
      "\n",
      "0 7\n",
      "-. .\n",
      "7\n",
      "278 3\n",
      ". . .\n",
      "5 - .\n",
      "- - . . .\n",
      ". 7 .- -\n",
      "7\n",
      "\n",
      "--\n",
      "---\n",
      "\n",
      "-\n",
      "2 0 .\n",
      "1 . .\n",
      "\n",
      "-\n",
      "\n",
      ".\n",
      "7 - .\n",
      "1\n",
      "\n",
      "-\n",
      "-\n",
      ". -\n",
      "\n",
      "- -\n",
      "\n",
      "\n",
      "-\n",
      "-.. -\n",
      "-\n",
      ". 1 -\n",
      "--\n",
      "\n",
      "--\n",
      "7\n",
      "\n",
      "-\n",
      "..\n",
      ".\n",
      "\n",
      "450 .-\n",
      "- 74\n",
      "4 -\n",
      "--\n",
      ". - .\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      ".\n",
      ". . . .-.. .\n",
      "7\n",
      "-- . .\n",
      "\n",
      "\n",
      "7\n",
      "\n",
      "-\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      ".-\n",
      "\n",
      "4\n",
      "1\n",
      "2.\n",
      "4 . -\n",
      "\n",
      ".\n",
      "\n",
      "2\n",
      "-\n",
      "- .\n",
      "\n",
      "-\n",
      "4 . . .\n",
      ". . -\n",
      ". 4 .\n",
      ".\n",
      "\n",
      "4 -\n",
      "-\n",
      ".\n",
      "- . .\n",
      ". -\n",
      "-\n",
      ".\n",
      "\n",
      "7\n",
      "\n",
      ".\n",
      "\n",
      "-\n",
      ".\n",
      "\n",
      "\n",
      "17 -\n",
      "\n",
      "\n",
      ".\n",
      ". .\n",
      ". -\n",
      "- - .\n",
      "7\n",
      "\n",
      ".\n",
      ".-\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      "-\n",
      "-\n",
      "0 - . -\n",
      "6 .\n",
      "- .. - .\n",
      "-\n",
      ". -\n",
      ".\n",
      "\n",
      "\n",
      "- . . . .\n",
      "\n",
      "-\n",
      "-. . .- . 1\n",
      "- - -\n",
      "2--\n",
      "2\n",
      "\n",
      "\n",
      "4\n",
      "\n",
      "\n",
      "7 -\n",
      "4\n",
      "\n",
      "7\n",
      "7 -\n",
      ".\n",
      ".\n",
      "\n",
      "\n",
      ". -\n",
      "4\n",
      ".\n",
      ". . - 7\n",
      ". - -. .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      "\n",
      "-\n",
      "\n",
      "3\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      "..\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-. .\n",
      "\n",
      ".\n",
      "\n",
      "5\n",
      "\n",
      "\n",
      "\n",
      "- - .\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "-\n",
      ".\n",
      ".\n",
      "\n",
      "\n",
      "4. -\n",
      ".\n",
      "\n",
      "\n",
      ".\n",
      ".\n",
      "\n",
      "1\n",
      ".\n",
      ".\n",
      "-\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "-\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      ".\n",
      "-\n",
      "\n",
      "\n",
      "- 2\n",
      "- . - . . .\n",
      "-\n",
      ". -\n",
      "4. - . -\n",
      "- -\n",
      ".\n",
      ".\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "- .\n",
      "5\n",
      ".\n",
      "\n",
      "-\n",
      ".\n",
      "\n",
      "-\n",
      "- -.. .\n",
      ".\n",
      "..\n",
      ". -\n",
      "\n",
      "- 2\n",
      "-\n",
      "-\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [181], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m success:\n\u001b[0;32m     11\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m pic \u001b[39m=\u001b[39m get_contours(frame)\n\u001b[0;32m     13\u001b[0m text \u001b[39m=\u001b[39m getText(pic, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[39mprint\u001b[39m(text)\n",
      "Cell \u001b[1;32mIn [176], line 13\u001b[0m, in \u001b[0;36mget_contours\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_contours\u001b[39m(img):\n\u001b[1;32m---> 13\u001b[0m     contours, _ \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mfindContours(process(img), cv2\u001b[39m.\u001b[39;49mRETR_TREE, cv2\u001b[39m.\u001b[39;49mCHAIN_APPROX_NONE)\n\u001b[0;32m     14\u001b[0m     r1, r2 \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(contours, key\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mcontourArea)[\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     15\u001b[0m     x, y, w, h \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mboundingRect(np\u001b[39m.\u001b[39mr_[r1, r2])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#path = \"vid_1.MOV\"\n",
    "\n",
    "#vidcap = cv2.VideoCapture(path)\n",
    "#success,frame = vidcap.read()\n",
    "#framenbr = 0\n",
    "\n",
    "#while success:\n",
    "    #cv2.imwrite(\"frame%d.png\" % framenbr, frame[500:1020,1080:1680]) \n",
    "    #success,frame = vidcap.read()\n",
    "    #if not success:\n",
    "        #break\n",
    "    #pic = get_contours(frame)\n",
    "    #text = getText(pic, True)\n",
    "    #print(text)\n",
    "    #framenbr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchID = '704.035.93'\n",
    "images = splitImage(mainImage)\n",
    "for image in images:\n",
    "    text = getText(image, True)\n",
    "    text = re.sub('[^\\d\\.]', '', text)\n",
    "    if(searchID in text):\n",
    "        print(\"Found\")\n",
    "        break\n",
    "    print(\"Not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1024fc1c84d9d393894ff0ae508183bc66ab1dc33e63cfc602fbbf4a77e727ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
